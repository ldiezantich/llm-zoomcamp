{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8565c5ed",
   "metadata": {},
   "source": [
    "# Simple Semantic Search\n",
    "\n",
    " notes following the [3.2 video](https://www.youtube.com/watch?v=ptByfB_YcEg&ab_channel=DataTalksClub%E2%AC%9B)\n",
    "\n",
    "# Step 0: Start up docker for ElasticSearch\n",
    "```\n",
    "docker run -it \\\n",
    "    --rm \\\n",
    "    --name elasticsearch \\\n",
    "    -m 4GB \\\n",
    "    -p 9200:9200 \\\n",
    "    -p 9300:9300 \\\n",
    "    -e \"discovery.type=single-node\" \\\n",
    "    -e \"xpack.security.enabled=false\" \\\n",
    "    docker.elastic.co/elasticsearch/elasticsearch:8.4.3\n",
    "```\n",
    "\n",
    "# Step 1: Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b991541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download documents\n",
    "!wget -nc https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/refs/heads/main/01-intro/documents.json\n",
    "\n",
    "# load documents.json and flatten them\n",
    "import json\n",
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "\n",
    "documents = []\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9650b4",
   "metadata": {},
   "source": [
    "# Step 2: Create Embeddings using Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.float_ = np.float64\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "model.encode('simple sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52090742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings for the documents\n",
    "operations = []\n",
    "for doc in documents:\n",
    "    doc[\"text_vector\"] = model.encode(doc[\"text\"]).tolist()\n",
    "    operations.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c0e4d",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "source": [
    "# Step 3: Create an ElasticSearch Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "# create mapping\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\", \n",
    "                \"dims\": 768, \n",
    "                \"index\": True, \n",
    "                \"similarity\": \"cosine\"\n",
    "                },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# create index\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name,ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name,body=index_settings)\n",
    "\n",
    "# add documents to index\n",
    "for doc in tqdm(operations):\n",
    "    try: \n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6953d08",
   "metadata": {},
   "source": [
    "# Step 5: Create end user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac55c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = 'windows or mac?'\n",
    "search_term_vector = model.encode(search_term)\n",
    "\n",
    "query = {\n",
    "    \"field\": \"text_vector\",\n",
    "    \"query_vector\": search_term_vector,\n",
    "    \"k\": 5,\n",
    "    \"num_candidates\": 1000\n",
    "}\n",
    "\n",
    "res = es_client.search(\n",
    "    index=index_name, \n",
    "    knn=query, \n",
    "    source=[\"text\", \"section\", \"question\", \"course\"]\n",
    "    )\n",
    "\n",
    "res[\"hits\"][\"hits\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
